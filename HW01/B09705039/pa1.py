# Read file.
path = 'input.txt'
f = open(path, 'r')
all = f.read()
f.close()

# Tokenization.
# signs that can be ignored: We only listed a few here, if needed more we can add more. 
nonAlphanumeric = [",", ".", "'", ";", ":", '"', "@", "!", "(", ")", "[", "]", "<", ">"]
for i in nonAlphanumeric:
    all = all.replace(i, " ")
    
# hyphens: ignore int his case since there is no hyphen in the input
all = all.replace("-", "")

tokenize = all.split()

# Lowercasing everything.
lowercase = []
for i in tokenize:
    lowercase.append(i.lower())
    
# Stemming using Porterâ€™s algorithm.
# import module
from nltk.stem import PorterStemmer
ps = PorterStemmer()

after_stemming = []
for w in lowercase:
    after_stemming.append(ps.stem(w))
    
# Stopword removal.
# Read stopwords file. stopwords.txt is generated by nltk.
path = 'stopwords.txt'
f2 = open(path, 'r')
stop_words = f2.read()
f2.close()

# Removal start.
stop_words = stop_words.split()
stopword_removed = []
for w in after_stemming:
    if w not in stop_words:
        stopword_removed.append(w)
        
# Save the result as a txt file.
path = 'result.txt'
f = open(path, 'w')

final_array = []
for i in stopword_removed:
    final_array.append(i + "\n")
f.writelines(final_array)
f.close()